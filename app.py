# --- START OF FILE app.py ---

import gradio as gr
from TTS.api import TTS
import torch
import torch.serialization # <-- Import serialization module
from TTS.tts.configs.xtts_config import XttsConfig # <-- Import the first config class
from TTS.tts.models.xtts import XttsAudioConfig # <-- Import the second required class
from TTS.config.shared_configs import BaseDatasetConfig # <-- Import the third required class
from TTS.tts.models.xtts import XttsArgs # <-- Import the fourth required class (arguments)
import traceback # For printing detailed errors
import os # To handle file paths robustly

# --- Add ALL required classes to safe globals BEFORE loading the model ---
# This is necessary for newer PyTorch versions with stricter loading defaults
torch.serialization.add_safe_globals([
    XttsConfig,
    XttsAudioConfig,
    BaseDatasetConfig,
    XttsArgs
])
# -----------------------------------------------------------------------

if torch.cuda.is_available():
    device = "cuda"
elif torch.backends.mps.is_available():
    # MPS support in PyTorch and libraries like TTS can still be experimental or incomplete
    # Falling back to CPU is often safer for compatibility.
    print("ØªØ­Ø°ÙŠØ±: MPS Ù…ØªØ§Ø­ ÙˆÙ„ÙƒÙ† Ø§Ù„Ø¯Ø¹Ù… Ù‚Ø¯ ÙŠÙƒÙˆÙ† ØºÙŠØ± Ù…ÙƒØªÙ…Ù„. Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… CPU.")
    device = "cpu"
else:
    device = "cpu"

print(f"Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¬Ù‡Ø§Ø²: {device}") # Added print statement for clarity

# Setting default device might not be strictly necessary for TTS,
# as it handles device placement internally with .to(device),
# but it doesn't hurt.
# torch.set_default_device(device) # You can comment this out if needed

print("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ TTS...")
# Load the model (this is where torch.load is called internally)
# Ensure the model path is correct relative to your execution directory or use an absolute path
model_path = "tts_models/multilingual/multi-dataset/xtts_v2"
if not os.path.exists(model_path):
     # Fallback or attempt download logic if needed, for now, just warn
     print(f"ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ '{model_path}'. ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ø³Ø§Ø± Ø£Ùˆ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªÙ… ØªÙ†Ø²ÙŠÙ„Ù‡.")
     # You might want to exit or raise an error here if the model is essential
     # exit()

tts = TTS(model_path) # Use the variable
print("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ TTS. Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù†Ù‚Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø²...")
tts.to(device)
print(f"ØªÙ… Ù†Ù‚Ù„ Ù†Ù…ÙˆØ°Ø¬ TTS Ø¥Ù„Ù‰ {device}.")

# --- ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£Ù…Ø«Ù„Ø© ÙˆØ§Ù„Ù…Ù„ÙØ§Øª ---
examples_dir = "examples"
female_example = os.path.join(examples_dir, "female.wav")
male_example = os.path.join(examples_dir, "male.wav")

if not os.path.exists(examples_dir):
    os.makedirs(examples_dir)
    print(f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£Ù…Ø«Ù„Ø©: {examples_dir}")
    # You might need to add dummy wav files or download real examples here
    # For now, we'll just check existence of files below

if not os.path.exists(female_example):
    print(f"ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ù…Ø«Ø§Ù„ {female_example}. Ù‚Ø¯ Ù„Ø§ ØªØ¹Ù…Ù„ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù…Ù‡.")
    # Set female_example to None or a default if critical, or handle in examples list
    female_example = None # Or provide a path to a valid fallback

if not os.path.exists(male_example):
    print(f"ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ù…Ø«Ø§Ù„ {male_example}. Ù‚Ø¯ Ù„Ø§ ØªØ¹Ù…Ù„ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù…Ù‡.")
    # Set male_example to None or a default if critical, or handle in examples list
    male_example = None # Or provide a path to a valid fallback
# ---------------------------------------------

def predict(prompt, language, audio_file_pth, agree):
    # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø± Ù‡Ù†Ø§ Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
    if audio_file_pth and not os.path.exists(audio_file_pth):
         gr.Error(f"Ù…Ù„Ù Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ Ø§Ù„Ù…Ø­Ø¯Ø¯ '{audio_file_pth}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")
         return None, None

    if not agree:
        # Use gr.Error for errors, gr.Warning for non-critical warnings
        gr.Error("ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø±ÙˆØ· ÙˆØ§Ù„Ø£Ø­ÙƒØ§Ù…!")
        # Return None or default values for outputs when there's an error
        return None, None
    if not prompt:
        gr.Warning("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø¨Ø¹Ø¶ Ø§Ù„Ù†Øµ.")
        return None, None
    if not audio_file_pth:
        gr.Warning("ÙŠØ±Ø¬Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ù…Ù„Ù ØµÙˆØªÙŠ Ù…Ø±Ø¬Ø¹ÙŠ Ø£Ùˆ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯Ù‡.")
        return None, None

    try:
        output_path = "output.wav"
        print(f"Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª Ù„Ù„Ù†Øµ: '{prompt[:50]}...'")
        tts.tts_to_file(
            text=prompt,
            file_path=output_path,
            speaker_wav=audio_file_pth,
            language=language, # ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ù‡Ø°Ù‡ Ø±Ù…ÙˆØ² Ø§Ù„Ù„ØºØ§Øª Ù…Ø«Ù„ 'en', 'ar'
        )
        print(f"ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª Ø¨Ù†Ø¬Ø§Ø­ ÙˆØ­ÙØ¸Ù‡ ÙÙŠ {output_path}")

        # --- MODIFIED FOR CORRECT GRADIO OUTPUT ---
        # gr.Video can directly display the waveform from an audio path
        # Return the audio path for BOTH the video and audio components
        return (
            output_path, # <-- Pass path directly to gr.Video for waveform
            output_path, # <-- Pass path to gr.Audio for playback
        )
        # ------------------------------------------

    except Exception as e:
        print(f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª: {e}")
        traceback.print_exc() # Print the full traceback for debugging
        gr.Error(f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙˆÙ„ÙŠØ¯: {e}")
        return None, None

# --- ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†ØµÙˆØµ Ù‡Ù†Ø§ ---
title_ar = "ØªØ·ÙˆÙŠØ± : Ø­Ø³Ø§Ù… ÙØ¶Ù„ Ù‚Ø¯ÙˆØ± - ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…"

description_ar = """
<div dir="rtl" style="text-align: right;">
<a href="https://github.com/housamkh83/hossam-ai-suite">hossam</a> Ù‡Ùˆ Ù†Ù…ÙˆØ°Ø¬ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª ÙŠØªÙŠØ­ Ù„Ùƒ Ø§Ø³ØªÙ†Ø³Ø§Ø® Ø§Ù„Ø£ØµÙˆØ§Øª Ø¨Ù„ØºØ§Øª Ù…Ø®ØªÙ„ÙØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ù‚Ø·Ø¹ ØµÙˆØªÙŠ Ù…Ø±Ø¬Ø¹ÙŠ Ù‚ØµÙŠØ± (3 Ø«ÙˆØ§Ù†Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„).
<br/>
ØªÙ… Ø¨Ù†Ø§Ø¡ XTTS Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ TortoiseØŒ ÙˆÙŠØªØ¶Ù…Ù† ØªØºÙŠÙŠØ±Ø§Øª Ù…Ù‡Ù…Ø© ØªØ¬Ø¹Ù„ Ø§Ø³ØªÙ†Ø³Ø§Ø® Ø§Ù„ØµÙˆØª Ø¹Ø¨Ø± Ø§Ù„Ù„ØºØ§Øª ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ø§Ù… Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª Ø£Ù…Ø±Ù‹Ø§ Ø³Ù‡Ù„Ø§Ù‹ Ù„Ù„ØºØ§ÙŠØ©.
<br/>
Ù‡Ø°Ø§ Ù‡Ùˆ Ù†ÙØ³ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙŠ ÙŠØ¹Ù…Ù„ Ø¨Ù‡ hossam-ai-suite Ùˆ ØªØ±Ø®ÙŠØµ MITØŒ ÙˆÙ„ÙƒÙ†Ù†Ø§ Ù†Ø·Ø¨Ù‚ Ù‡Ù†Ø§ Ø¨Ø¹Ø¶ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ù„Ø¬Ø¹Ù„Ù‡ Ø£Ø³Ø±Ø¹ ÙˆØ¯Ø¹Ù… Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø§Ù„Ù…ØªØ¯ÙÙ‚ (streaming).
</div>
"""

article_ar = """
<div dir="rtl" style="text-align: right; margin:20px auto;">
<p>Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…Ùƒ Ù„Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©ØŒ ÙØ¥Ù†Ùƒ ØªÙˆØ§ÙÙ‚ Ø¹Ù„Ù‰ Ø´Ø±ÙˆØ· ØªØ±Ø®ÙŠØµ Ù†Ù…ÙˆØ°Ø¬ ğŸ† ØµÙÙ†Ø¹ Ø¨Ø¥Ø±Ø§Ø¯Ø© ØªØªØ­Ø¯Ù‰ Ø§Ù„Ù…Ø³ØªØ­ÙŠÙ„: Ø­Ø³Ø§Ù… ÙØ¶Ù„ Ù‚Ø¯ÙˆØ± ğŸ† Ø§Ù„Ø¹Ø§Ù… Ø§Ù„Ù…ØªØ§Ø­Ø© Ø¹Ù„Ù‰: https://github.com/housamkh83/hossam-ai-suite</p>
<p><b>Ù…Ù„Ø§Ø­Ø¸Ø©:</b> Ù‚Ø¯ ØªØ³ØªØºØ±Ù‚ Ø¹Ù…Ù„ÙŠØ© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª Ø¨Ø¹Ø¶ Ø§Ù„ÙˆÙ‚Øª Ø§Ø¹ØªÙ…Ø§Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ Ø·ÙˆÙ„ Ø§Ù„Ù†Øµ ÙˆÙ…ÙˆØ§ØµÙØ§Øª Ø¬Ù‡Ø§Ø²Ùƒ (CPU/GPU).</p>
</div>
"""

# Update example paths checking if they exist
examples_ar = []
if female_example:
    examples_ar.extend([
        [
            "Once when I was six years old I saw a magnificent picture.",
            "en",
            female_example,
            True,
        ],
        [
            "Un tempo lontano, quando avevo sei anni, vidi un magnifico disegno.",
            "it",
            female_example,
            True,
        ],
        [
            "Hola, esto es una prueba en espaÃ±ol.",
            "es",
            female_example,
            True,
        ],
        [ # Ù…Ø«Ø§Ù„ Ø¹Ø±Ø¨ÙŠ
            "Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹ Ø¨ÙƒÙ… ÙÙŠ ÙˆØ§Ø¬Ù‡Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù….",
            "ar", # Ø±Ù…Ø² Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
            female_example,
            True
        ]
    ])
if male_example:
     examples_ar.extend([
        [
            "Lorsque j'avais six ans j'ai vu, une fois, une magnifique image.",
            "fr",
            male_example,
            True,
        ],
        [
            "Hallo, dies ist ein Test auf Deutsch.",
            "de",
            male_example,
            True,
        ],
     ])

# Make sure examples list is not empty if both files were missing
if not examples_ar:
     print("ØªØ­Ø°ÙŠØ±: Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ù…Ø«Ù„Ø© Ù…ØªØ§Ø­Ø© Ø¨Ø³Ø¨Ø¨ Ø¹Ø¯Ù… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©.")
     examples_ar = None # Gradio handles None examples gracefully

# Ensure example files exist or handle potential errors
# (For simplicity, assuming they are present as in the original code)

with gr.Blocks() as demo:
    gr.Markdown(f"<h1 style='text-align: center;'>{title_ar}</h1>")
    gr.Markdown(description_ar)

    with gr.Row():
        with gr.Column(scale=2):
            text_prompt = gr.Textbox(
                label="Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¯Ø®Ù„",
                info="Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù… (ÙŠÙÙØ¶Ù„ Ø¬Ù…Ù„Ø© Ø£Ùˆ Ø¬Ù…Ù„ØªÙŠÙ† Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬)",
                value="Ø£Ù‡Ù„Ø§Ù‹ Ø¨ÙƒÙ… ÙÙŠ ØªØ¬Ø±Ø¨Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø­Ø³Ø§Ù… ÙØ¶Ù„ Ù‚Ø¯ÙˆØ±.", # Ù…Ø«Ø§Ù„ Ù†Øµ Ø¹Ø±Ø¨ÙŠ
                rtl=True # Ù…Ø­Ø§Ø°Ø§Ø© Ù„Ù„ÙŠÙ…ÙŠÙ† Ù„Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
            )
            language = gr.Dropdown(
                label="Ù„ØºØ© Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¯Ø®Ù„",
                info="Ø§Ø®ØªØ± Ù„ØºØ© Ø§Ù„Ù†Øµ Ø§Ù„Ø°ÙŠ Ø£Ø¯Ø®Ù„ØªÙ‡ (ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ·Ø§Ø¨Ù‚ Ø§Ù„Ù†Øµ)",
                # Ø±Ù…ÙˆØ² Ø§Ù„Ù„ØºØ§Øª ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ Ù„ÙÙ‡Ù…Ù‡Ø§ Ø¨ÙˆØ§Ø³Ø·Ø© TTS
                choices=[
                    "en", "es", "fr", "de", "it", "pt", "pl", "tr", "ru", "nl",
                    "cs", "ar", "zh-cn", "ja", "ko", "hu", "hi"
                ],
                value="ar", # Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù‡ÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
            )
            ref_audio = gr.Audio(
                label="Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ (3+ Ø«ÙˆØ§Ù†ÙŠ)",
                # Removed 'info' argument as it's not supported in older versions maybe
                type="filepath", # Keep as filepath as TTS expects a path
                # Use a default value that exists, handle None if necessary
                value=female_example if female_example else male_example if male_example else None,
            )
            agree_checkbox = gr.Checkbox(
                label="Ø£ÙˆØ§ÙÙ‚ Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø±ÙˆØ·",
                value=False, # Start unchecked
                info="Ø£ÙˆØ§ÙÙ‚ Ø¹Ù„Ù‰ Ø´Ø±ÙˆØ· ØªØ±Ø®ÙŠØµ Ù†Ù…ÙˆØ°Ø¬ ",
            )
            submit_btn = gr.Button("ğŸ”Š ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ø§Ù…") # Ø¥Ø¶Ø§ÙØ© Ø£ÙŠÙ‚ÙˆÙ†Ø© ØµÙˆØª

        with gr.Column(scale=1):
            # Both Video and Audio components will receive the output_path
            video_output = gr.Video(label="ğŸ“ˆ Ø¹Ø±Ø¶ Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„ØµÙˆØªÙŠØ©", interactive=False)
            audio_output = gr.Audio(label="ğŸ§ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…ÙØ®Ø±ÙØ¬", type="filepath", interactive=False)

    gr.Markdown(article_ar)

    if examples_ar: # Only show examples if list is not None
        gr.Examples(
            examples=examples_ar,
            inputs=[text_prompt, language, ref_audio, agree_checkbox],
            # Outputs match the return order from predict: (video_path, audio_path)
            outputs=[video_output, audio_output],
            fn=predict, # Link examples button to the predict function
            cache_examples=False, # Disable caching for TTS during development/testing if needed
            label="Ø£Ù…Ø«Ù„Ø©" # ØªØ³Ù…ÙŠØ© Ù‚Ø³Ù… Ø§Ù„Ø£Ù…Ø«Ù„Ø©
        )

    # Connect the button click to the predict function
    submit_btn.click(
        fn=predict,
        inputs=[text_prompt, language, ref_audio, agree_checkbox],
        outputs=[video_output, audio_output] # Order matches return from predict
    )

# Use queue() for handling multiple users and longer processing times
# Enable debug=True for more detailed logs in the console
# Add share=True to create a public link (requires internet connection)
print("Ø¬Ø§Ø±ÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©...")
demo.queue().launch(debug=True) # Ø£Ø¶Ù share=True Ù‡Ù†Ø§ Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª Ø±Ø§Ø¨Ø·Ù‹Ø§ Ø¹Ø§Ù…Ù‹Ø§: demo.queue().launch(debug=True, share=True)

