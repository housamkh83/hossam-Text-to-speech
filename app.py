# --- START OF FILE app.py ---

import gradio as gr
from TTS.api import TTS
import torch
import torch.serialization # <-- Import serialization module
from TTS.tts.configs.xtts_config import XttsConfig # <-- Import the first config class
from TTS.tts.models.xtts import XttsAudioConfig # <-- Import the second required class
from TTS.config.shared_configs import BaseDatasetConfig # <-- Import the third required class
from TTS.tts.models.xtts import XttsArgs # <-- Import the fourth required class (arguments)
import traceback # For printing detailed errors
import os # To handle file paths robustly

# --- Add ALL required classes to safe globals BEFORE loading the model ---
# This is necessary for newer PyTorch versions with stricter loading defaults
torch.serialization.add_safe_globals([
    XttsConfig,
    XttsAudioConfig,
    BaseDatasetConfig,
    XttsArgs
])
# -----------------------------------------------------------------------

if torch.cuda.is_available():
    device = "cuda"
elif torch.backends.mps.is_available():
    # MPS support in PyTorch and libraries like TTS can still be experimental or incomplete
    # Falling back to CPU is often safer for compatibility.
    print("ุชุญุฐูุฑ: MPS ูุชุงุญ ูููู ุงูุฏุนู ูุฏ ูููู ุบูุฑ ููุชูู. ุณูุชู ุงุณุชุฎุฏุงู CPU.")
    device = "cpu"
else:
    device = "cpu"

print(f"ุณูุชู ุงุณุชุฎุฏุงู ุงูุฌูุงุฒ: {device}") # Added print statement for clarity

# Setting default device might not be strictly necessary for TTS,
# as it handles device placement internally with .to(device),
# but it doesn't hurt.
# torch.set_default_device(device) # You can comment this out if needed

print("ุฌุงุฑู ุชุญููู ูููุฐุฌ TTS...")
# Load the model (this is where torch.load is called internally)
# Ensure the model path is correct relative to your execution directory or use an absolute path
model_path = "tts_models/multilingual/multi-dataset/xtts_v2"
if not os.path.exists(model_path):
     # Fallback or attempt download logic if needed, for now, just warn
     print(f"ุชุญุฐูุฑ: ูู ูุชู ุงูุนุซูุฑ ุนูู ูุณุงุฑ ุงููููุฐุฌ '{model_path}'. ุชุฃูุฏ ูู ุตุญุฉ ุงููุณุงุฑ ุฃู ุฃู ุงููููุฐุฌ ุชู ุชูุฒููู.")
     # You might want to exit or raise an error here if the model is essential
     # exit()

tts = TTS(model_path) # Use the variable
print("ุชู ุชุญููู ูููุฐุฌ TTS. ุฌุงุฑู ุงูููู ุฅูู ุงูุฌูุงุฒ...")
tts.to(device)
print(f"ุชู ููู ูููุฐุฌ TTS ุฅูู {device}.")

# --- ุชุฃูุฏ ูู ูุฌูุฏ ูุฌูุฏ ุงูุฃูุซูุฉ ูุงููููุงุช ---
examples_dir = "examples"
female_example = os.path.join(examples_dir, "female.wav")
male_example = os.path.join(examples_dir, "male.wav")

if not os.path.exists(examples_dir):
    os.makedirs(examples_dir)
    print(f"ุชู ุฅูุดุงุก ูุฌูุฏ ุงูุฃูุซูุฉ: {examples_dir}")
    # You might need to add dummy wav files or download real examples here
    # For now, we'll just check existence of files below

if not os.path.exists(female_example):
    print(f"ุชุญุฐูุฑ: ูู ูุชู ุงูุนุซูุฑ ุนูู ููู ุงููุซุงู {female_example}. ูุฏ ูุง ุชุนูู ุงูุฃูุซูุฉ ุงูุชู ุชุณุชุฎุฏูู.")
    # Set female_example to None or a default if critical, or handle in examples list
    female_example = None # Or provide a path to a valid fallback

if not os.path.exists(male_example):
    print(f"ุชุญุฐูุฑ: ูู ูุชู ุงูุนุซูุฑ ุนูู ููู ุงููุซุงู {male_example}. ูุฏ ูุง ุชุนูู ุงูุฃูุซูุฉ ุงูุชู ุชุณุชุฎุฏูู.")
    # Set male_example to None or a default if critical, or handle in examples list
    male_example = None # Or provide a path to a valid fallback
# ---------------------------------------------

def predict(prompt, language, audio_file_pth, agree):
    # ุฅุนุงุฏุฉ ุงูุชุญูู ูู ุงููุณุงุฑ ููุง ูุจู ุงูุงุณุชุฎุฏุงู
    if audio_file_pth and not os.path.exists(audio_file_pth):
         gr.Error(f"ููู ุงูุตูุช ุงููุฑุฌุนู ุงููุญุฏุฏ '{audio_file_pth}' ุบูุฑ ููุฌูุฏ!")
         return None, None

    if not agree:
        # Use gr.Error for errors, gr.Warning for non-critical warnings
        gr.Error("ูุฑุฌู ุงูููุงููุฉ ุนูู ุงูุดุฑูุท ูุงูุฃุญูุงู!")
        # Return None or default values for outputs when there's an error
        return None, None
    if not prompt:
        gr.Warning("ูุฑุฌู ุฅุฏุฎุงู ุจุนุถ ุงููุต.")
        return None, None
    if not audio_file_pth:
        gr.Warning("ูุฑุฌู ุชูุฏูู ููู ุตูุชู ูุฑุฌุนู ุฃู ุงูุชุฃูุฏ ูู ูุฌูุฏู.")
        return None, None

    try:
        output_path = "output.wav"
        print(f"ุฌุงุฑู ุชูููุฏ ุงูุตูุช ูููุต: '{prompt[:50]}...'")
        tts.tts_to_file(
            text=prompt,
            file_path=output_path,
            speaker_wav=audio_file_pth,
            language=language, # ูุฌุจ ุฃู ุชููู ูุฐู ุฑููุฒ ุงููุบุงุช ูุซู 'en', 'ar'
        )
        print(f"ุชู ุชูููุฏ ุงูุตูุช ุจูุฌุงุญ ูุญูุธู ูู {output_path}")

        # --- MODIFIED FOR CORRECT GRADIO OUTPUT ---
        # gr.Video can directly display the waveform from an audio path
        # Return the audio path for BOTH the video and audio components
        return (
            output_path, # <-- Pass path directly to gr.Video for waveform
            output_path, # <-- Pass path to gr.Audio for playback
        )
        # ------------------------------------------

    except Exception as e:
        print(f"ุฎุทุฃ ุฃุซูุงุก ุชูููุฏ ุงูุตูุช: {e}")
        traceback.print_exc() # Print the full traceback for debugging
        gr.Error(f"ุฎุทุฃ ุฃุซูุงุก ุงูุชูููุฏ: {e}")
        return None, None

# --- ุชุฑุฌูุฉ ุงููุตูุต ููุง ---
title_ar = "ุชุทููุฑ : ุญุณุงู ูุถู ูุฏูุฑ - ุชุญููู ุงููุต ุฅูู ููุงู"

description_ar = """
<div dir="rtl" style="text-align: right;">
<a href="https://github.com/housamkh83/hossam-ai-suite">hossam</a> ูู ูููุฐุฌ ูุชูููุฏ ุงูุตูุช ูุชูุญ ูู ุงุณุชูุณุงุฎ ุงูุฃุตูุงุช ุจูุบุงุช ูุฎุชููุฉ ุจุงุณุชุฎุฏุงู ููุทุน ุตูุชู ูุฑุฌุนู ูุตูุฑ (3 ุซูุงูู ุนูู ุงูุฃูู).
<br/>
ุชู ุจูุงุก XTTS ุนูู ูููุฐุฌ Tortoiseุ ููุชุถูู ุชุบููุฑุงุช ูููุฉ ุชุฌุนู ุงุณุชูุณุงุฎ ุงูุตูุช ุนุจุฑ ุงููุบุงุช ูุชูููุฏ ุงูููุงู ูุชุนุฏุฏ ุงููุบุงุช ุฃูุฑูุง ุณููุงู ููุบุงูุฉ.
<br/>
ูุฐุง ูู ููุณ ุงููููุฐุฌ ุงูุฐู ูุนูู ุจู hossam-ai-suite ู ุชุฑุฎูุต MITุ ูููููุง ูุทุจู ููุง ุจุนุถ ุงูุชุญุณููุงุช ูุฌุนูู ุฃุณุฑุน ูุฏุนู ุงูุงุณุชุฏูุงู ุงููุชุฏูู (streaming).
</div>
"""

article_ar = """
<div dir="rtl" style="text-align: right; margin:20px auto;">
<p>ุจุงุณุชุฎุฏุงูู ููุฐู ุงููุงุฌูุฉ ุงูุชุฌุฑูุจูุฉุ ูุฅูู ุชูุงูู ุนูู ุดุฑูุท ุชุฑุฎูุต ูููุฐุฌ ๐ ุตููุน ุจุฅุฑุงุฏุฉ ุชุชุญุฏู ุงููุณุชุญูู: ุญุณุงู ูุถู ูุฏูุฑ ๐ ุงูุนุงู ุงููุชุงุญุฉ ุนูู: https://github.com/housamkh83/hossam-ai-suite</p>
<p><b>ููุงุญุธุฉ:</b> ูุฏ ุชุณุชุบุฑู ุนูููุฉ ุชูููุฏ ุงูุตูุช ุจุนุถ ุงูููุช ุงุนุชูุงุฏูุง ุนูู ุทูู ุงููุต ูููุงุตูุงุช ุฌูุงุฒู (CPU/GPU).</p>
</div>
"""

# Update example paths checking if they exist
examples_ar = []
if female_example:
    examples_ar.extend([
        [
            "Once when I was six years old I saw a magnificent picture.",
            "en",
            female_example,
            True,
        ],
        [
            "Un tempo lontano, quando avevo sei anni, vidi un magnifico disegno.",
            "it",
            female_example,
            True,
        ],
        [
            "Hola, esto es una prueba en espaรฑol.",
            "es",
            female_example,
            True,
        ],
        [ # ูุซุงู ุนุฑุจู
            "ุฃููุงู ูุณููุงู ุจูู ูู ูุงุฌูุฉ ุชุญููู ุงููุต ุฅูู ููุงู.",
            "ar", # ุฑูุฒ ุงููุบุฉ ุงูุนุฑุจูุฉ
            female_example,
            True
        ]
    ])
if male_example:
     examples_ar.extend([
        [
            "Lorsque j'avais six ans j'ai vu, une fois, une magnifique image.",
            "fr",
            male_example,
            True,
        ],
        [
            "Hallo, dies ist ein Test auf Deutsch.",
            "de",
            male_example,
            True,
        ],
     ])

# Make sure examples list is not empty if both files were missing
if not examples_ar:
     print("ุชุญุฐูุฑ: ูุง ุชูุฌุฏ ุฃูุซูุฉ ูุชุงุญุฉ ุจุณุจุจ ุนุฏู ุงูุนุซูุฑ ุนูู ุงููููุงุช ุงููุฑุฌุนูุฉ.")
     examples_ar = None # Gradio handles None examples gracefully

# Ensure example files exist or handle potential errors
# (For simplicity, assuming they are present as in the original code)

with gr.Blocks() as demo:
    gr.Markdown(f"<h1 style='text-align: center;'>{title_ar}</h1>")
    gr.Markdown(description_ar)

    with gr.Row():
        with gr.Column(scale=2):
            text_prompt = gr.Textbox(
                label="ุงููุต ุงููุฏุฎู",
                info="ุฃุฏุฎู ุงููุต ุงููุฑุงุฏ ุชุญูููู ุฅูู ููุงู (ูููุถู ุฌููุฉ ุฃู ุฌููุชูู ููุญุตูู ุนูู ุฃูุถู ุงููุชุงุฆุฌ)",
                value="ุฃููุงู ุจูู ูู ุชุฌุฑุจุฉ ุชุญููู ุงููุต ุฅูู ููุงู ุจุงุณุชุฎุฏุงู ุญุณุงู ูุถู ูุฏูุฑ.", # ูุซุงู ูุต ุนุฑุจู
                rtl=True # ูุญุงุฐุงุฉ ูููููู ูููุต ุงูุนุฑุจู
            )
            language = gr.Dropdown(
                label="ูุบุฉ ุงููุต ุงููุฏุฎู",
                info="ุงุฎุชุฑ ูุบุฉ ุงููุต ุงูุฐู ุฃุฏุฎูุชู (ูุฌุจ ุฃู ูุทุงุจู ุงููุต)",
                # ุฑููุฒ ุงููุบุงุช ุชุจูู ููุง ูู ูููููุง ุจูุงุณุทุฉ TTS
                choices=[
                    "en", "es", "fr", "de", "it", "pt", "pl", "tr", "ru", "nl",
                    "cs", "ar", "zh-cn", "ja", "ko", "hu", "hi"
                ],
                value="ar", # ุงููููุฉ ุงูุงูุชุฑุงุถูุฉ ูู ุงูุนุฑุจูุฉ
            )
            ref_audio = gr.Audio(
                label="ุงูุตูุช ุงููุฑุฌุนู (3+ ุซูุงูู)",
                # Removed 'info' argument as it's not supported in older versions maybe
                type="filepath", # Keep as filepath as TTS expects a path
                # Use a default value that exists, handle None if necessary
                value=female_example if female_example else male_example if male_example else None,
            )
            agree_checkbox = gr.Checkbox(
                label="ุฃูุงูู ุนูู ุงูุดุฑูุท",
                value=False, # Start unchecked
                info="ุฃูุงูู ุนูู ุดุฑูุท ุชุฑุฎูุต ูููุฐุฌ ",
            )
            submit_btn = gr.Button("๐ ุชูููุฏ ุงูููุงู") # ุฅุถุงูุฉ ุฃููููุฉ ุตูุช

        with gr.Column(scale=1):
            # Both Video and Audio components will receive the output_path
            video_output = gr.Video(label="๐ ุนุฑุถ ุงูููุฌุฉ ุงูุตูุชูุฉ", interactive=False)
            audio_output = gr.Audio(label="๐ง ุงูุตูุช ุงูููุฎุฑูุฌ", type="filepath", interactive=False)

    gr.Markdown(article_ar)

    if examples_ar: # Only show examples if list is not None
        gr.Examples(
            examples=examples_ar,
            inputs=[text_prompt, language, ref_audio, agree_checkbox],
            # Outputs match the return order from predict: (video_path, audio_path)
            outputs=[video_output, audio_output],
            fn=predict, # Link examples button to the predict function
            cache_examples=False, # Disable caching for TTS during development/testing if needed
            label="ุฃูุซูุฉ" # ุชุณููุฉ ูุณู ุงูุฃูุซูุฉ
        )

    # Connect the button click to the predict function
    submit_btn.click(
        fn=predict,
        inputs=[text_prompt, language, ref_audio, agree_checkbox],
        outputs=[video_output, audio_output] # Order matches return from predict
    )

# Use queue() for handling multiple users and longer processing times
# Enable debug=True for more detailed logs in the console
# Add share=True to create a public link (requires internet connection)
print("ุฌุงุฑู ุชุดุบูู ุงููุงุฌูุฉ...")
demo.queue().launch(debug=True) # ุฃุถู share=True ููุง ุฅุฐุง ุฃุฑุฏุช ุฑุงุจุทูุง ุนุงููุง: demo.queue().launch(debug=True, share=True)

